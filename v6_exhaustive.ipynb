{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def usp_comp(amat):\n",
    "    \"\"\" Return the size of the smallest unique-shortest-path complement of a graph.\n",
    "    \"\"\"\n",
    "    # Accept graph, graph6 string, or matrix input\n",
    "    \n",
    "    try:\n",
    "        nn = amat.ncols()\n",
    "    except AttributeError:\n",
    "        amat = amat.adjacency_matrix()\n",
    "        nn = amat.ncols()\n",
    "    if not amat:\n",
    "        return nn - 1\n",
    "    A = amat + 2\n",
    "    AA = A + 0\n",
    "    compsize = nn - 1\n",
    "    while min(min([yy for yy in xx if yy]) for xx in AA) == 1:\n",
    "        compsize -= 1\n",
    "        AA = AA*A\n",
    "    \n",
    "    return compsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Glabel(G):\n",
    "    return G.canonical_label().graph6_string()\n",
    "\n",
    "\n",
    "def edgeclasses(G):\n",
    "    Aut = G.automorphism_group()\n",
    "    needs = {(xx[0], xx[1]): True for xx in G.edges()}\n",
    "    while needs:\n",
    "        anedge = next(iter(needs))\n",
    "        yield anedge\n",
    "        for xx in Aut.orbit(anedge, action='OnPairs'):\n",
    "            if (xx[0], xx[1]) in needs:\n",
    "                del needs[(xx[0], xx[1])]\n",
    "            if (xx[1], xx[0]) in needs:\n",
    "                del needs[(xx[1], xx[0])]\n",
    "\n",
    "                \n",
    "def deletions(G):\n",
    "    for ed in edgeclasses(G):\n",
    "        H = G.copy()\n",
    "        H.delete_edge(ed)\n",
    "        yield Glabel(H)\n",
    "\n",
    "        \n",
    "def contractions(G):\n",
    "    # Also covers isolated vertex deletion\n",
    "    for ed in edgeclasses(G):\n",
    "        H = G.copy()\n",
    "        H.contract_edge(ed)\n",
    "        yield Glabel(H)\n",
    "    if 0 in G.degree():\n",
    "        H = G.copy()\n",
    "        H.delete_vertex(G.degree().index(0))\n",
    "        yield Glabel(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prior_minors(previous_nn, previous_edge_count):\n",
    "    import ast\n",
    "    \n",
    "    path_prefix = 'minor_minimal_graphs'\n",
    "    \n",
    "    uspcm_list = []\n",
    "\n",
    "    with open(path_prefix + f'/uspcm_dict/full_uspcm_dict_after_n_{previous_nn}_edges-{previous_edge_count}.txt', 'r') as infile:\n",
    "        stored_uspcm = infile.read()\n",
    "\n",
    "        uspcm_list.extend(ast.literal_eval(stored_uspcm))\n",
    "\n",
    "\n",
    "    minimals_list = []\n",
    "\n",
    "    with open(path_prefix + f'/all_minimals/all_minimals_after_n_{previous_nn}_edges-{previous_edge_count}.txt', 'r') as infile:\n",
    "        stored_minimals = infile.read()\n",
    "\n",
    "        minimals_list.extend(ast.literal_eval(stored_minimals))\n",
    "        \n",
    "    return uspcm_list, minimals_list\n",
    "\n",
    "\n",
    "def write_computed_minors(nn, edge_count, uspcm_dict, minimals):\n",
    "    # Craig added this to save to files\n",
    "    path_prefix = 'minor_minimal_graphs'\n",
    "    \n",
    "    with open(path_prefix + \n",
    "              f'/all_minimals/all_minimals_after_n_{nn}_edges-{edge_count}.txt', 'w') as outfile:\n",
    "        outfile.write(str(minimals))\n",
    "\n",
    "    with open(path_prefix + \n",
    "              f'/uspcm_dict/full_uspcm_dict_after_n_{nn}_edges-{edge_count}.txt', 'w') as outfile:\n",
    "        outfile.write(str(uspcm_dict))\n",
    "        \n",
    "        \n",
    "def write_computed_data_v2(nn, edge_count, uspcm_dict, minimals):\n",
    "    # Craig added this to save to files\n",
    "    path_prefix = 'minor_minimal_graphs'\n",
    "    with open(path_prefix +\n",
    "              f'/all_minimals/all_minimals_after_n_{nn}_edges-{edge_count}.txt', 'w') as outfile:\n",
    "        outfile.write(str(minimals))\n",
    "\n",
    "    with open(path_prefix +\n",
    "              f'/uspcm_dict/full_uspcm_dict_after_n_{nn}_edges-{edge_count}.txt', 'w') as outfile:\n",
    "        outfile.write(str(uspcm_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def exhaustive_search_range_nn(previous_nn, last_nn_to_do):\n",
    "#     previous_edge_count = 1\n",
    "#     path_prefix = 'minor_minimal_graphs'\n",
    "\n",
    "#     if previous_nn > 1:\n",
    "#         # Import previously computed uspc_dict and minimals\n",
    "#         uspcm_dict, minimals = read_prior_minors(previous_nn, previous_edge_count)\n",
    "#     elif previous_nn == 1:\n",
    "#         uspcm_dict = [[{Glabel(Graph(0)): 0}], [{Glabel(Graph(1)): 0}]]\n",
    "#         minimals = [[Graph(Glabel(Graph(1))).graph6_string()]]\n",
    "\n",
    "#     for nn in range(previous_nn+1, last_nn_to_do+1):\n",
    "\n",
    "#         # Craig added to write to file\n",
    "#         with open(path_prefix + f'/minimal_for_n_{nn}.txt', 'w') as outfile:\n",
    "\n",
    "\n",
    "#             print(f'Working on graphs with {nn} vertices.')\n",
    "#             G = Graph(nn).complement() # Graph(nn) is empty graph on nn vertices so Graph(nn).complement() is K_n\n",
    "#             uspcm_dict.append([{Glabel(G): nn - 2}])\n",
    "#             edcount = Integer((nn*(nn-1))/2)\n",
    "#             while edcount:\n",
    "#                 print(f'{edcount} edges:')\n",
    "#                 uspcm_dict[-1].append(dict())\n",
    "#                 # First pass: set values, giving every superminor a chance.\n",
    "#                 for amat in uspcm_dict[-1][-2]:\n",
    "#                     mine = uspcm_dict[-1][-2][amat]\n",
    "#                     G = Graph(amat)\n",
    "#                     for xx in deletions(G):\n",
    "#                         if xx in uspcm_dict[-1][-1]:\n",
    "#                             # print(f'Updating {Graph(xx).graph6_string()} from {uspcm_dict[-1][-1][xx]}', end='')\n",
    "#                             # print(f' to {mine}.')\n",
    "#                             old = uspcm_dict[-1][-1][xx]\n",
    "#                             uspcm_dict[-1][-1][xx] = min(mine, old)\n",
    "#                         else:\n",
    "#                             # print(f'Setting {Graph(xx).graph6_string()} to {usp_comp(xx)}.')\n",
    "#                             old = usp_comp(Graph(xx))\n",
    "#                             uspcm_dict[-1][-1][xx] = min(mine, old)\n",
    "#                     for xx in contractions(G):\n",
    "#                         edplace = Integer((nn - 1)*(nn - 2)/2) - Graph(xx).size()\n",
    "#                         old = uspcm_dict[-2][edplace][xx]\n",
    "#                         if old > mine:\n",
    "#                             print(f'Exception found: {G.graph6_string()} has uspc {mine}', end='')\n",
    "#                             print(f' with minor {Graph(xx).graph6_string()} of uspc {uspcm_dict[-2][edplace][xx]}.')\n",
    "#                 # Second pass: check for minimality\n",
    "#                 for amat in uspcm_dict[-1][-2]:\n",
    "#                     mine = uspcm_dict[-1][-2][amat]\n",
    "#                     G = Graph(amat)\n",
    "#                     for xx in deletions(G):\n",
    "#                         if mine == uspcm_dict[-1][-1][xx]:\n",
    "#                             break\n",
    "#                     else:\n",
    "#                         for xx in contractions(G):\n",
    "#                             edplace = Integer((nn - 1)*(nn - 2)/2) - Graph(xx).size()\n",
    "#                             if mine == uspcm_dict[-2][edplace][xx]:\n",
    "#                                 break\n",
    "#                         else:\n",
    "#                             print(f'Minor minimal for {mine}: {G.graph6_string()}.')\n",
    "\n",
    "#                             # Craig added this to write to also write to file\n",
    "#                             outfile.write(f'Minor minimal for {mine}: {G.graph6_string()}.\\n')\n",
    "\n",
    "#                             while len(minimals) < mine + 1:\n",
    "#                                 minimals.append([])\n",
    "#                             minimals[mine].append(G.graph6_string())\n",
    "                            \n",
    "                            \n",
    "#                 # Write/save the computed results for |V(G)| = nn, |E(G)| = edcount\n",
    "#                 write_computed_minors(nn, edcount, uspcm_dict, minimals)\n",
    "                \n",
    "#                 edcount -= 1\n",
    "#         print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exhaustive_search_range_nn(previous_nn=1, last_nn_to_do=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_latest_worked_size():\n",
    "#     import os, re\n",
    "#     path_prefix = 'minor_minimal_graphs'\n",
    "    \n",
    "#     worked_Ns = []\n",
    "#     worked_Edges = []\n",
    "\n",
    "#     for filename in os.listdir(path_prefix + '/all_minimals'):\n",
    "\n",
    "\n",
    "#         if 'minimals_after_n_' in filename:\n",
    "#             worked_Ns.append(int(re.findall('_n_[0-9]', filename)[0].split('_')[-1]))\n",
    "#             worked_Edges.append(int(re.findall('edges-[0-9]+', filename)[0].split('-')[-1]))\n",
    "\n",
    "\n",
    "#     worked_vertices_edges = list(zip(worked_Ns, worked_Edges))\n",
    "\n",
    "#     max_worked_N = min(max(worked_Ns), nn)\n",
    "#     worked_edges_for_max_N = []\n",
    "#     for N, E in worked_vertices_edges:\n",
    "#         if N == max(worked_Ns):\n",
    "#             worked_edges_for_max_N.append(E)\n",
    "\n",
    "#     min_E_for_max_N = min(worked_edges_for_max_N)\n",
    "    \n",
    "#     return (max_worked_N, min_E_for_max_N)\n",
    "\n",
    "\n",
    "\n",
    "# def get_previously_computed(max_worked_N, min_worked_E):\n",
    "#     import ast\n",
    "    \n",
    "#     path_prefix = 'minor_minimal_graphs'\n",
    "    \n",
    "#     uspcm_list = []\n",
    "\n",
    "#     with open(path_prefix +\n",
    "#               f'/uspcm_dict/full_uspcm_dict_after_n_{max_worked_N}_edges-{min_worked_E}.txt', 'r') as infile:\n",
    "#         stored_uspcm = infile.read()\n",
    "\n",
    "#         uspcm_list.extend(ast.literal_eval(stored_uspcm))\n",
    "\n",
    "\n",
    "#     minimals_list = []\n",
    "\n",
    "#     with open(path_prefix +\n",
    "#               f'/all_minimals/all_minimals_after_n_{max_worked_N}_edges-{min_worked_E}.txt', 'r') as infile:\n",
    "#         stored_minimals = infile.read()\n",
    "\n",
    "#         minimals_list.extend(ast.literal_eval(stored_minimals))\n",
    "        \n",
    "#     return uspcm_list, minimals_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_status():\n",
    "    import ast\n",
    "    \n",
    "    path_prefix = 'minor_minimal_graphs'\n",
    "    try:\n",
    "        with open(path_prefix + '/completed_status.txt', 'r') as infile:\n",
    "            status_dict = ast.literal_eval(infile.read())\n",
    "    except FileNotFoundError:\n",
    "        status_dict = {}\n",
    "        \n",
    "    return status_dict\n",
    "\n",
    "def update_status(status_dict):\n",
    "    path_prefix = 'minor_minimal_graphs'\n",
    "\n",
    "    with open(path_prefix + '/completed_status.txt', 'w') as outfile:\n",
    "        outfile.write(status_dict)\n",
    "        \n",
    "        \n",
    "def get_last_status(nn, status_dict):\n",
    "    vert_edge_tuples = list(status_dict.keys())\n",
    "    \n",
    "    last_tup = sorted(vert_edge_tuples, key=lambda x: (-x[0], x[1]))[0]\n",
    "\n",
    "    if len(status_dict[last_tup]) == 1:\n",
    "        return (last_tup, ' '.join(status_dict[last_tup][0].split()[0:2]))\n",
    "    elif len(status_dict[last_tup]) == 2:\n",
    "        return (last_tup, ' '.join(status_dict[last_tup][1].split()[0:2]))\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_previously_computed(last_worked_N, last_worked_E):\n",
    "    import ast\n",
    "    \n",
    "    path_prefix = 'minor_minimal_graphs'\n",
    "    \n",
    "    uspcm_list = []\n",
    "\n",
    "    with open(path_prefix +\n",
    "              f'/uspcm_dict/full_uspcm_dict_after_n_{last_worked_N}_edges-{last_worked_E}.txt', 'r') as infile:\n",
    "        stored_uspcm = infile.read()\n",
    "\n",
    "        uspcm_list.extend(ast.literal_eval(stored_uspcm))\n",
    "\n",
    "\n",
    "    minimals_list = []\n",
    "\n",
    "    with open(path_prefix +\n",
    "              f'/all_minimals/all_minimals_after_n_{last_worked_N}_edges-{last_worked_E}.txt', 'r') as infile:\n",
    "        stored_minimals = infile.read()\n",
    "\n",
    "        minimals_list.extend(ast.literal_eval(stored_minimals))\n",
    "        \n",
    "    return uspcm_list, minimals_list\n",
    "\n",
    "\n",
    "\n",
    "def progressBar(iterable, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ', printEnd = \"\\r\"):\n",
    "    import datetime\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    total = len(iterable)\n",
    "    # Progress Bar Printing Function\n",
    "    def printProgressBar (iteration):\n",
    "        percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "        filledLength = int(length * iteration // total)\n",
    "        bar = fill * filledLength + '-' * (length - filledLength)\n",
    "        print(f'\\r{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} {prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Initial Call\n",
    "    printProgressBar(0)\n",
    "    # Update Progress Bar\n",
    "    for i, item in enumerate(iterable):\n",
    "        yield item\n",
    "        printProgressBar(i + 1)\n",
    "    # Print New Line on Complete\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def first_pass(nn): # for some reason nn was taking on a different value if I used it as a global variable without passing it as a parameter\n",
    "    print(f'Edcount after entering first_pass() function: {edcount}')\n",
    "    \n",
    "    one_percent = len(uspcm_dict[-1][-2]) // 100\n",
    "    num_graphs_worked = 0\n",
    "    \n",
    "    # First pass: set values, giving every superminor a chance.\n",
    "    for amat in progressBar(uspcm_dict[-1][-2], \n",
    "                            prefix = f'Progress on 1st pass:', \n",
    "                            suffix = 'Complete', length = 50):\n",
    "\n",
    "        mine = uspcm_dict[-1][-2][amat]\n",
    "        G = Graph(amat)\n",
    "        for xx in deletions(G):\n",
    "            if xx in uspcm_dict[-1][-1]:\n",
    "                # print(f'Updating {Graph(xx).graph6_string()} from {uspcm_dict[-1][-1][xx]}', end='')\n",
    "                # print(f' to {mine}.')\n",
    "                old = uspcm_dict[-1][-1][xx]\n",
    "                uspcm_dict[-1][-1][xx] = min(mine, old)\n",
    "            else:\n",
    "                # print(f'Setting {Graph(xx).graph6_string()} to {usp_comp(xx)}.')\n",
    "                old = usp_comp(Graph(xx))\n",
    "                uspcm_dict[-1][-1][xx] = min(mine, old)\n",
    "        for xx in contractions(G):\n",
    "            edplace = Integer((nn - 1)*(nn - 2)/2) - Graph(xx).size()\n",
    "            old = uspcm_dict[-2][edplace][xx]\n",
    "            if old > mine:\n",
    "                print(f'Exception found: {G.graph6_string()} has uspc {mine}', end='')\n",
    "                print(f' with minor {Graph(xx).graph6_string()} of uspc {uspcm_dict[-2][edplace][xx]}.')\n",
    "                \n",
    "        \n",
    "        # Save to file every one percent of the way through\n",
    "        num_graphs_worked += 1\n",
    "        if num_graphs_worked % one_percent == 0:\n",
    "            write_computed_minors(nn, edcount, uspcm_dict, minimals)\n",
    "        \n",
    "        \n",
    "\n",
    "def second_pass(nn):\n",
    "    \n",
    "    one_percent = len(uspcm_dict[-1][-2]) // 100\n",
    "    num_graphs_worked = 0\n",
    "    \n",
    "    # Second pass: check for minimality\n",
    "    for amat in progressBar(uspcm_dict[-1][-2], \n",
    "                        prefix = f'Progress on 2nd pass, checking for minimality:', \n",
    "                        suffix = 'Complete', length = 50):\n",
    "        mine = uspcm_dict[-1][-2][amat]\n",
    "        G = Graph(amat)\n",
    "        for xx in deletions(G):\n",
    "            if mine == uspcm_dict[-1][-1][xx]:\n",
    "                break\n",
    "        else:\n",
    "            for xx in contractions(G):\n",
    "                edplace = Integer((nn - 1)*(nn - 2)/2) - Graph(xx).size()\n",
    "                if mine == uspcm_dict[-2][edplace][xx]:\n",
    "                    break\n",
    "            else:\n",
    "                print(f'Minor minimal for {mine}: {G.graph6_string()}.')\n",
    "\n",
    "                # Craig added this to write to also write to file\n",
    "                with open(path_prefix + f'/minimal_for_n_{nn}.txt', 'a') as outfile:\n",
    "                    outfile.write(f'Minor minimal for {mine}: {G.graph6_string()}.\\n')\n",
    "\n",
    "                while len(minimals) < mine + 1:\n",
    "                    minimals.append([])\n",
    "                minimals[mine].append(G.graph6_string())\n",
    "\n",
    "\n",
    "        # Save to file every one percent of the way through\n",
    "        num_graphs_worked += 1\n",
    "        if num_graphs_worked % one_percent == 0:\n",
    "            write_computed_minors(nn, edcount, uspcm_dict, minimals)\n",
    "\n",
    "\n",
    "    # Update status\n",
    "    status_dict[(nn, edcount)].append('Second Pass Done')\n",
    "    update_status(str(status_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exhaustive_search_limited_edge_counts(nn, first_edge_count, last_edge_count_to_do, \n",
    "                                          load_from_previous_nn=False, force_computation=True):\n",
    "    import os\n",
    "    \n",
    "    global path_prefix\n",
    "    global status_dict    \n",
    "    global uspcm_dict\n",
    "    global minimals\n",
    "    global edcount\n",
    "    global max_worked_N\n",
    "    \n",
    "    path_prefix = 'minor_minimal_graphs'\n",
    "    if 'all_minimals' not in os.listdir(path_prefix):\n",
    "        os.mkdir(path_prefix + '/all_minimals')\n",
    "    if 'uspcm_dict' not in os.listdir(path_prefix):\n",
    "        os.mkdir(path_prefix + '/uspcm_dict')\n",
    "    \n",
    "    status_dict = get_status()\n",
    "    last_status = get_last_status(nn, status_dict)\n",
    "    \n",
    "    \n",
    "    if last_status[0][0] >= nn and last_status[0][1] <= first_edge_count and last_status[1] == 'Second Pass':\n",
    "        if force_computation:\n",
    "            if first_edge_count == 0:\n",
    "                last_status = ((nn-1, 1), 'Second Pass')\n",
    "            else:\n",
    "                last_status = ((nn, first_edge_count), 'Second Pass')\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    \n",
    "#     if last_status[0][0] > nn or (last_status[0][0] == nn and last_status[0][1] >= edge_count):\n",
    "#         last_status = ((nn, edge_count+1), 'Second Pass')\n",
    "    print(last_status)\n",
    "    skip_first_pass = False\n",
    "    try:\n",
    "        if last_status[1] == 'First Pass':\n",
    "            skip_first_pass = True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    if nn <= 2:\n",
    "        uspcm_dict = [[{Glabel(Graph(0)): 0}], [{Glabel(Graph(1)): 0}]]\n",
    "        minimals = [[Graph(Glabel(Graph(1))).graph6_string()]]\n",
    "        edcount = 1\n",
    "        \n",
    "    elif load_from_previous_nn == True:\n",
    "        # Import previously computed uspc_dict and minimals\n",
    "#         max_worked_N, edcount = find_latest_worked_size()\n",
    "        last_worked_N, edcount = last_status[0]\n",
    "        uspcm_dict, minimals = get_previously_computed(last_worked_N, edcount)\n",
    "    \n",
    "\n",
    "    print(f'Working on graphs with {nn} vertices.')\n",
    "    if edcount == 1:\n",
    "        G = Graph(nn).complement() # Graph(nn) is empty graph on nn vertices so Graph(nn).complement() is K_n\n",
    "        uspcm_dict.append([{Glabel(G): nn - 2}])\n",
    "        edcount = Integer((nn*(nn-1))/2)\n",
    "    else:\n",
    "        edcount = edcount - 1\n",
    "\n",
    "    while edcount >= last_edge_count_to_do:\n",
    "        print(f'\\n{edcount} edges:')\n",
    "        uspcm_dict[-1].append(dict())\n",
    "\n",
    "\n",
    "        # For informational purposes only\n",
    "        num_to_check = len(uspcm_dict[-1][-2])\n",
    "        print(f'Need to go through {num_to_check} graphs on {nn} vertices with {edcount} edges.\\nStart time: {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}.')\n",
    "\n",
    "# Still need to modify the code to only go through graphs that haven't already been computed\n",
    "# graphs_left_to_check_list = list(set(graph6_list) - set(worked_graphs_list))\n",
    "        \n",
    "        if skip_first_pass:\n",
    "            continue\n",
    "        else:\n",
    "            print(f'Edge count before entering first_pass() function: {edcount}')\n",
    "            first_pass(nn)\n",
    "            \n",
    "#             # Update status\n",
    "#             status_dict.update({(nn, edcount):['First Pass Done']})\n",
    "#             update_status(str(status_dict))\n",
    "\n",
    "\n",
    "#         second_pass(nn)\n",
    "\n",
    "\n",
    "        edcount -= 1\n",
    "    print('\\n\\nAll Done!\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exhaustive_search_limited_edge_counts(nn=8, previous_edge_count=6, last_edge_count_to_do=1, load_from_previous_nn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exhaustive_search_limited_edge_counts(nn=9, previous_edge_count=1, last_edge_count_to_do=19, load_from_previous_nn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exhaustive_search_limited_edge_counts(nn=9, previous_edge_count=19, last_edge_count_to_do=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exhaustive_search_limited_edge_counts(nn=10, previous_edge_count=1, last_edge_count_to_do=40, load_from_previous_nn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for nn in range(1,9):\n",
    "#     exhaustive_search_limited_edge_counts(nn, previous_edge_count=1, last_edge_count_to_do=1,\n",
    "#                                           load_from_previous_nn=True, force_computation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_edge_count = get_last_status(10, get_status())[0][1]\n",
    "next_edge_count = previous_edge_count - 1\n",
    "next_edge_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10, 26), 'Second Pass')\n",
      "Working on graphs with 10 vertices.\n",
      "\n",
      "25 edges:\n",
      "Need to go through 1061159 graphs on 10 vertices with 25 edges.\n",
      "Start time: 2021-06-13 02:07:04.\n",
      "Edge count before entering first_pass() function: 25\n",
      "Edcount after entering first_pass() function: 25\n",
      "2021-06-13 02:07:08 Progress on 1st pass: |--------------------------------------------------| 0.0% Complete\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8d421c33abb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m exhaustive_search_limited_edge_counts(Integer(10), first_edge_count=next_edge_count,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                       \u001b[0mlast_edge_count_to_do\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_edge_count\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                       load_from_previous_nn=True, force_computation=True)\n",
      "\u001b[0;32m<ipython-input-9-beb2a9e161f6>\u001b[0m in \u001b[0;36mexhaustive_search_limited_edge_counts\u001b[0;34m(nn, first_edge_count, last_edge_count_to_do, load_from_previous_nn, force_computation)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Edge count before entering first_pass() function: {edcount}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mfirst_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m#             # Update status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-446551186bed>\u001b[0m in \u001b[0;36mfirst_pass\u001b[0;34m(nn)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Save to file after every graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mwrite_computed_minors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muspcm_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4df39db0b4f7>\u001b[0m in \u001b[0;36mwrite_computed_minors\u001b[0;34m(nn, edge_count, uspcm_dict, minimals)\u001b[0m\n\u001b[1;32m     32\u001b[0m     with open(path_prefix + \n\u001b[1;32m     33\u001b[0m               f'/uspcm_dict/full_uspcm_dict_after_n_{nn}_edges-{edge_count}.txt', 'w') as outfile:\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moutfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muspcm_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/cysignals/signals.pyx\u001b[0m in \u001b[0;36mcysignals.signals.python_check_interrupt\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exhaustive_search_limited_edge_counts(10, first_edge_count=next_edge_count,\n",
    "                                      last_edge_count_to_do=next_edge_count-3,\n",
    "                                      load_from_previous_nn=True, force_computation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
