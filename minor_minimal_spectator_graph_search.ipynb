{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd1e94-d658-4153-b0be-920331193124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will iterate over all graphs on nn vertices from nn = start_n to nn = stop_n - 1.\n",
    "# Can use shortcut_edges = edcount to start at edcount edges instead of starting with the complete graph on start_n vertices;\n",
    "# this is useful if the kernel gets interrupted while working on graphs on 10 vertices since it takes multiple days to process\n",
    "# all 11million+ graphs on 10 vertices.\n",
    "\n",
    "# These parameters can be set here or can be set in a command line instance and then run the notebook from the command line.\n",
    "# start_n = 2\n",
    "# stop_n = 5\n",
    "# shortcut_edges = False\n",
    "\n",
    "\n",
    "# Do you want to remove previously calculated data?\n",
    "remove_old_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544e676a-aea3-4370-a2ae-1cb64c58470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of directory in which to save the data files.\n",
    "path_prefix = 'data'\n",
    "\n",
    "# Removes the results of previous calculations\n",
    "if remove_old_data == True:\n",
    "    import shutil\n",
    "    \n",
    "    try:\n",
    "        shutil.rmtree(path_prefix)\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5318de7-e400-4496-86fe-c5af7cfcf198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the read/write functions\n",
    "# Eventually replace this local load to loading from the public github repo\n",
    "load('spectator_floor_number_read_write_functions.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0420d1-8f82-49c8-9a65-c7df2e918abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython # use cython to speed up computations -- This jupyter magic call cannot be in a .py script file\n",
    "\n",
    "# use garbage collection to manage memory usage\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "\n",
    "def usp_comp(amat):\n",
    "    \"\"\" Return the spectator number of the graph, which is defined to be\n",
    "    the size of the smallest unique-shortest-path complement of a graph.\n",
    "    \n",
    "    :param amat: A graph or adjacency matrix of a graph.\n",
    "    \"\"\"\n",
    "    # Accept graph or matrix input\n",
    "    try:\n",
    "        # Get size from the number of columns, if amat is a matrix\n",
    "        nn = amat.ncols()\n",
    "    except AttributeError:\n",
    "        # If amat is a graph or graph6_string, convert to adjacency matrix\n",
    "        amat = amat.adjacency_matrix()\n",
    "        # Get size from number of colummns\n",
    "        nn = amat.ncols()\n",
    "    if not amat:\n",
    "        return nn - 1\n",
    "    \n",
    "    # Use fact that (i,j)-entry of A^k is the number of i-j walks of length k\n",
    "    # to determine the length of the longest unique shortest path (the largest k\n",
    "    # for which there exists an (i,j)-entry of A^k equal to 1.)\n",
    "    A = amat + 2\n",
    "    AA = A + 0\n",
    "    compsize = nn - 1\n",
    "    while min(min([yy for yy in xx if yy]) for xx in AA) == 1:\n",
    "        compsize -= 1\n",
    "        AA = AA*A\n",
    "    \n",
    "    return compsize\n",
    "\n",
    "\n",
    "\n",
    "def Glabel(G):\n",
    "    \"\"\"\n",
    "    Returns the graph6_string of the canonical labeling of graph G using the sage algorithm\n",
    "    to determine the canonical labeling.\n",
    "    \n",
    "    :param G: A graph object.\n",
    "    \"\"\"\n",
    "    return G.canonical_label(algorithm='sage').graph6_string()\n",
    "\n",
    "\n",
    "def edgeclasses(G):\n",
    "    \"\"\"\n",
    "    Generator function to generate the automorphism groups of the edges in graph G.\n",
    "    \n",
    "    :param G: A graph object.\n",
    "    \"\"\"\n",
    "    Aut = G.automorphism_group()\n",
    "    needs = {(xx[0], xx[1]): True for xx in G.edges()}\n",
    "    while needs:\n",
    "        anedge = next(iter(needs))\n",
    "        yield anedge\n",
    "        for xx in Aut.orbit(anedge, action='OnPairs'):\n",
    "            if (xx[0], xx[1]) in needs:\n",
    "                del needs[(xx[0], xx[1])]\n",
    "            if (xx[1], xx[0]) in needs:\n",
    "                del needs[(xx[1], xx[0])]\n",
    "\n",
    "                \n",
    "def deletions(G):\n",
    "    \"\"\"\n",
    "    Generator function to generate the minors of G which are achievable by deleting a single edge\n",
    "    from G.\n",
    "    Returns the graph6_string of the canonical labeling.\n",
    "    \n",
    "    :param G: A graph object.\n",
    "    \"\"\"\n",
    "    for ed in edgeclasses(G):\n",
    "        H = G.copy()\n",
    "        H.delete_edge(ed)\n",
    "        yield Glabel(H)\n",
    "\n",
    "        \n",
    "def contractions(G):\n",
    "    \"\"\"\n",
    "    Generator function to generate the minors of G which are achievable by either contracting a single\n",
    "    edge in G or deleting a single isolated vertex in G.\n",
    "    Returns the graph6_string of the canonical labeling.\n",
    "    \n",
    "    :param G: A graph object.\n",
    "    \"\"\"\n",
    "    for ed in edgeclasses(G):\n",
    "        H = G.copy()\n",
    "        H.contract_edge(ed)\n",
    "        yield Glabel(H)\n",
    "    # Also covers isolated vertex deletion\n",
    "    if 0 in G.degree():\n",
    "        H = G.copy()\n",
    "        H.delete_vertex(G.degree().index(0))\n",
    "        yield Glabel(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c52ef6d-2f93-44cb-8072-9762902e31f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressBar(iterable, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    import datetime\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    total = len(iterable)\n",
    "    # Progress Bar Printing Function\n",
    "    def printProgressBar(iteration):\n",
    "        try:\n",
    "            percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "            filledLength = int(length * iteration // total)\n",
    "        except ZeroDivisionError:\n",
    "            percent = 100\n",
    "            filledLength = length\n",
    "        \n",
    "        bar = fill * filledLength + '-' * (length - filledLength)\n",
    "        print(f'\\r{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} {prefix} |{bar}| {percent}% {suffix}', end = printEnd, flush=False)\n",
    "    # Initial Call\n",
    "    printProgressBar(0)\n",
    "    # Update Progress Bar\n",
    "    for i, item in enumerate(iterable):\n",
    "        yield item\n",
    "        printProgressBar(i + 1)\n",
    "    # Print New Line on Complete\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82aabe6-6d0f-4daf-89e7-1a51a6bc38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_floor_first_pass():\n",
    "    \"\"\"\n",
    "    Determines the minor floor of the spectator number for all graphs on nn vertices and\n",
    "    edcount edges.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Used for both the progress bar and controlling how often the partial_uspcm_dict and \n",
    "    # partial_seen_dict are written to files.\n",
    "    one_percent = max(len(uspcm_dict[f'{nn}_verts'][f'{edcount}_edges']) // 100, 1)\n",
    "    fraction_percent = max(len(uspcm_dict[f'{nn}_verts'][f'{edcount}_edges']) // 1000, 1)\n",
    "    \n",
    "    if fraction_percent < 500:\n",
    "        save_percent = one_percent\n",
    "    else:\n",
    "        save_percent = fraction_percent\n",
    "    \n",
    "    # Used for progress bar\n",
    "    num_graphs_worked = 0\n",
    "    \n",
    "    # Iterate over all graphs on nn vertices and edcount edges\n",
    "    # amat is a graph6_string\n",
    "    for amat in progressBar(uspcm_dict[f'{nn}_verts'][f'{edcount}_edges'], \n",
    "                            prefix = f\"1st pass: nn={nn}, ee={edcount}:\", \n",
    "                            suffix = '', length = 40):\n",
    "        \n",
    "        # Skip those graphs whose spectator minor floor has already been determined.\n",
    "        if amat in seen_dict[f'{nn}_verts'][f'{edcount}_edges']:\n",
    "            num_graphs_worked += 1\n",
    "            continue\n",
    "        \n",
    "        # Skip the disconnected graphs since we can sum over connected components and save progress\n",
    "        if Graph(amat).is_connected() == False:\n",
    "            seen_dict[f'{nn}_verts'][f'{edcount}_edges'].add(amat)\n",
    "            write_partial_uspcm_dict(nn, edcount, uspcm_dict, path_prefix)\n",
    "            if edcount > 1:\n",
    "                write_partial_uspcm_dict(nn, edcount-1, uspcm_dict, path_prefix)\n",
    "            write_partial_seen_dict(nn, edcount, seen_dict, path_prefix)\n",
    "            num_graphs_worked += 1\n",
    "            continue\n",
    "            \n",
    "        # Current number that is potentially the spectator minor floor of graph amat\n",
    "        mine = uspcm_dict[f'{nn}_verts'][f'{edcount}_edges'][amat]\n",
    "        G = Graph(amat) # Generate the graph object whose graph6_string is amat\n",
    "\n",
    "        # For each minor xx of G, compare the computer spectator number of xx to the newly\n",
    "        # computed spectator number of G and update the claimed spectator minor floor of xx\n",
    "        # if necessary\n",
    "        for xx in deletions(G):\n",
    "            # Note: This is actually updating the number for the minor xx\n",
    "            if xx in uspcm_dict[f'{nn}_verts'][f'{edcount-1}_edges']:\n",
    "                old = uspcm_dict[f'{nn}_verts'][f'{edcount-1}_edges'][xx]\n",
    "                uspcm_dict[f'{nn}_verts'][f'{edcount-1}_edges'][xx] = min(mine, old)\n",
    "            else:\n",
    "                old = usp_comp(Graph(xx))\n",
    "                uspcm_dict[f'{nn}_verts'][f'{edcount-1}_edges'][xx] = min(mine, old)\n",
    "        for xx in contractions(G):\n",
    "            # Note: This is actually updating the number for the minor xx\n",
    "            xx_num_verts = Graph(xx).num_verts()\n",
    "            xx_num_edges = Graph(xx).num_edges()\n",
    "            old = uspcm_dict[f'{xx_num_verts}_verts'][f'{xx_num_edges}_edges'][xx]\n",
    "            if old > mine:\n",
    "                print(f'Exception found: {G.graph6_string()} has uspc {mine}', end='')\n",
    "                print(f' with minor {Graph(xx).graph6_string()} of uspc {uspcm_list[-2][edplace][xx]}.')\n",
    "                pass\n",
    "\n",
    "\n",
    "        # Save the progress\n",
    "        seen_dict[f'{nn}_verts'][f'{edcount}_edges'].add(amat)\n",
    "        num_graphs_worked += 1\n",
    "        # Save to file every one percent of the way through\n",
    "        if num_graphs_worked % save_percent == 0:\n",
    "            write_partial_uspcm_dict(nn, edcount, uspcm_dict, path_prefix)\n",
    "            if edcount > 1:\n",
    "                write_partial_uspcm_dict(nn, edcount-1, uspcm_dict, path_prefix)\n",
    "            write_partial_seen_dict(nn, edcount, seen_dict, path_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc4082d-379f-4496-8fb4-21394ea840f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to determine minimality in the second pass\n",
    "\n",
    "def check_minimality(G, uspcm_dict):\n",
    "    \"\"\"\n",
    "    Uses the dictionary of graphs and their spectator minor floor numbers calculated by the spec_floor_first_pass()\n",
    "    function to determine which graphs are minor minimal with respect to the spectator minor floor number.\n",
    "    \"\"\"\n",
    "\n",
    "    G, g6_str = get_canonical_graph(G)\n",
    "    G_spec_floor = get_spectator_floor(G, uspcm_dict)\n",
    "\n",
    "    for H in deletions(G):\n",
    "        if get_spectator_floor(H, uspcm_dict) == G_spec_floor:\n",
    "            # G is not minor minimal\n",
    "            return None\n",
    "    for H in contractions(G):\n",
    "        if get_spectator_floor(H, uspcm_dict) == G_spec_floor:\n",
    "            # G is not minor minimal\n",
    "            return None\n",
    "    else:\n",
    "        # G is minor minimal\n",
    "        return (g6_str, G_spec_floor)\n",
    "    \n",
    "    \n",
    "    \n",
    "def determine_minimals(nn, minimals_dict=None, uspcm_dict=None, save=False, path_prefix='data'):\n",
    "    \n",
    "    if uspcm_dict is None:\n",
    "        uspcm_dict = get_full_uspcm_dict()\n",
    "        \n",
    "    if minimals_dict is None:\n",
    "        minimals_dict_keys = [f'{kk}_spectators' for kk in range(10)]\n",
    "        minimals_dict = dict(zip(minimals_dict_keys, [set() for kk in range(10)]))\n",
    "        \n",
    "    \n",
    "    for edge_key in uspcm_dict.get(f'{nn}_verts'):\n",
    "        if save==True:\n",
    "            one_percent = max(len(uspcm_dict.get(f'{nn}_verts').get(edge_key)) // 100, 1)\n",
    "            fraction_percent = max(len(uspcm_dict.get(f'{nn}_verts').get(edge_key)) // 1000, 1)\n",
    "\n",
    "            if fraction_percent < 500:\n",
    "                save_percent = one_percent\n",
    "            else:\n",
    "                save_percent = fraction_percent\n",
    "            \n",
    "            \n",
    "        num_edges = edge_key.split('_')[0]\n",
    "        print(f'Working on graphs on {nn} vertices and {num_edges} edges...')\n",
    "        \n",
    "        num_graphs_worked = 0\n",
    "        \n",
    "        for g6_str in progressBar(uspcm_dict.get(f'{nn}_verts').get(edge_key), \n",
    "                            prefix = f\"2nd pass: nn={nn}, ee={num_edges}:\", \n",
    "                            suffix = '', length = 40):\n",
    "            if Graph(g6_str).is_connected():\n",
    "#                 print(g6_str)\n",
    "                result = check_minimality(g6_str, uspcm_dict)\n",
    "                if result is not None:\n",
    "                    G_spec_num = result[1]\n",
    "                    minimals_dict.get(f'{G_spec_num}_spectators').add(g6_str)\n",
    "\n",
    "            num_graphs_worked += 1\n",
    "                \n",
    "            if num_graphs_worked % save_percent == 0:\n",
    "                with open(path_prefix +\n",
    "                  f'/minimals_dict/minimals_dict_{nn}_verts_{num_edges}_edges.txt', 'w') as outfile:\n",
    "                    outfile.write(str(minimals_dict))\n",
    "                    \n",
    "    return minimals_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ec30da-51c4-4c57-bb21-20d87731fd0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on graphs with 2 vertices.\n",
      "Processing graphs with 2 vertices and 1 edges...\n",
      "2021-09-16 17:46:04 1st pass: nn=2, ee=1: |████████████████████████████████████████| 100.0% \n",
      "2021-09-16 17:46:04 2nd pass: nn=2, ee=1: |████████████████████████████████████████| 100.0% \n",
      "Working on graphs with 3 vertices.\n",
      "Processing graphs with 3 vertices and 3 edges...\n",
      "2021-09-16 17:46:04 1st pass: nn=3, ee=3: |████████████████████████████████████████| 100.0% \n",
      "2021-09-16 17:46:04 2nd pass: nn=3, ee=3: |████████████████████████████████████████| 100.0% \n",
      "Processing graphs with 3 vertices and 2 edges...\n",
      "2021-09-16 17:46:04 1st pass: nn=3, ee=2: |████████████████████████████████████████| 100.0% \n",
      "2021-09-16 17:46:04 2nd pass: nn=3, ee=2: |████████████████████████████████████████| 100.0% \n",
      "Processing graphs with 3 vertices and 1 edges...\n",
      "2021-09-16 17:46:04 1st pass: nn=3, ee=1: |████████████████████████████████████████| 100.0% \n",
      "2021-09-16 17:46:04 2nd pass: nn=3, ee=1: |████████████████████████████████████████| 100.0% \n",
      "Working on graphs with 4 vertices.\n",
      "Processing graphs with 4 vertices and 6 edges...\n",
      "2021-09-16 17:46:04 1st pass: nn=4, ee=6: |████████████████████████████████████████| 100.0% \n",
      "2021-09-16 17:46:04 2nd pass: nn=4, ee=6: |████████████████████████████████████████| 100.0% \n",
      "Processing graphs with 4 vertices and 5 edges...\n",
      "2021-09-16 17:46:04 1st pass: nn=4, ee=5: |████████████████████████████████████████| 100.0% \n",
      "2021-09-16 17:46:04 2nd pass: nn=4, ee=5: |████████████████████████████████████████| 100.0% \n",
      "Processing graphs with 4 vertices and 4 edges...\n",
      "2021-09-16 17:46:04 1st pass: nn=4, ee=4: |████████████████████████████████████████| 100.0% \n",
      "2021-09-16 17:46:04 2nd pass: nn=4, ee=4: |████████████████████████████████████████| 100.0% \n",
      "Processing graphs with 4 vertices and 3 edges...\n",
      "2021-09-16 17:46:04 1st pass: nn=4, ee=3: |████████████████████████████████████████| 100.0% \n",
      "2021-09-16 17:46:04 2nd pass: nn=4, ee=3: |████████████████████████████████████████| 100.0% \n",
      "Processing graphs with 4 vertices and 2 edges...\n",
      "2021-09-16 17:46:04 1st pass: nn=4, ee=2: |████████████████████████████████████████| 100.0% \n",
      "2021-09-16 17:46:04 2nd pass: nn=4, ee=2: |████████████████████████████████████████| 100.0% \n",
      "Processing graphs with 4 vertices and 1 edges...\n",
      "2021-09-16 17:46:04 1st pass: nn=4, ee=1: |████████████████████████████████████████| 100% \n",
      "2021-09-16 17:46:04 2nd pass: nn=4, ee=1: |████████████████████████████████████████| 100% \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check to see if the data directory is set up; otherwise, create the data directory\n",
    "if path_prefix not in os.listdir('.'):\n",
    "    os.mkdir(path_prefix)\n",
    "if 'minimals_dict' not in os.listdir(path_prefix):\n",
    "    os.mkdir(path_prefix + '/minimals_dict')\n",
    "if 'uspcm_dict' not in os.listdir(path_prefix):\n",
    "    os.mkdir(path_prefix + '/uspcm_dict')\n",
    "if 'full_uspcm_dict' not in os.listdir(path_prefix):\n",
    "    os.mkdir(path_prefix + '/full_uspcm_dict')\n",
    "if 'seen_dict' not in os.listdir(path_prefix):\n",
    "    os.mkdir(path_prefix + '/seen_dict')\n",
    "if 'completed_dict' not in os.listdir(path_prefix):\n",
    "    os.mkdir(path_prefix + '/completed_dict')\n",
    "\n",
    "    \n",
    "# Initialize the uspcm_dict: The dictionary that starts with the spectator numbers and ends with containing\n",
    "# the spectator minor floor numbers for the graphs.\n",
    "# Initialize minimals_dict: The dictionary of graphs which are minimal with respect to the spectator minor floor number.\n",
    "# Initialize seen_dict: The dictionary of graphs that have been processed by spec_floor_first_pass().\n",
    "# Initialize completed_dict: The dictionary of graphs that have been processed by second_pass().\n",
    "# All of these are nested dictionaries. uspcm_dict, seen_dict, and completed_dict have a first layer of keys of the form\n",
    "# {nn}_verts and second layer of keys of the form {ee}_edges. For example, the set of graphs on 4 vertices and 5 edges \n",
    "# that have been processed by second_pass() is accessable via completed_dict['4_verts']['5_edges']\n",
    "# The set of graphs which are spectator minor floor minimal for spectator number 3 is accessable via minimals_dict['3_spectators']\n",
    "uspcm_dict, minimals_dict, seen_dict, completed_dict = get_spectator_number_dictionaries(path_prefix)\n",
    "\n",
    "# The code depends on the partial_uspcm_dict for the graph on 0 vertices and for the graph on 1 vertex existing.\n",
    "starter_uspcm_dict = {'0_verts':{}, '1_verts':{}}\n",
    "starter_uspcm_dict['0_verts']['0_edges'] = {Glabel(Graph(0)): 0}\n",
    "starter_uspcm_dict['1_verts']['0_edges'] = {Glabel(Graph(1)): 0}\n",
    "write_partial_uspcm_dict(0, 0, starter_uspcm_dict, path_prefix)\n",
    "write_partial_uspcm_dict(1, 0, starter_uspcm_dict, path_prefix)\n",
    "\n",
    "\n",
    "# Iterate over all graphs on nn vertices from nn = start_n to nn = stop_n - 1.\n",
    "for nn in range(start_n, stop_n):\n",
    "    print(f'Working on graphs with {nn} vertices.')\n",
    "\n",
    "    # Start with the complete graph on nn vertices, work down to the empty graph on nn vertices\n",
    "    edcount = Integer((nn*(nn-1))/2)\n",
    "    K_n = Graph(nn).complement()\n",
    "    # Add to the uspcm_dict\n",
    "    uspcm_dict[f'{nn}_verts'][f'{K_n.num_edges()}_edges'] = {Glabel(K_n): nn - 2}\n",
    "    \n",
    "    if shortcut_edges:   \n",
    "        # Used if having to restart partway through graphs on 10 vertices since those 11million+ graphs take multiple days to process.\n",
    "        edcount = shortcut_edges\n",
    "    \n",
    "    while edcount:\n",
    "        # Working on graphs on nn vertices with decreasing number of edges down to 0 edges\n",
    "        print(f'Processing graphs with {nn} vertices and {edcount} edges...')\n",
    "        \n",
    "        # First pass: set values, giving every superminor a chance.\n",
    "        spec_floor_first_pass()\n",
    "        \n",
    "        # Save progress\n",
    "        write_partial_uspcm_dict(nn, edcount, uspcm_dict, path_prefix)\n",
    "        if edcount > 1:\n",
    "            write_partial_uspcm_dict(nn, edcount-1, uspcm_dict, path_prefix)\n",
    "#         write_full_uspcm_dict(uspcm_dict, path_prefix)\n",
    "        write_partial_seen_dict(nn, edcount, seen_dict, path_prefix)\n",
    "#         write_seen_dict(seen_dict, path_prefix)\n",
    "\n",
    "\n",
    "#         # Second pass: check for minimality\n",
    "# #         Something is incorrect with second_pass() resulting in not recognizing all of the minor minimal graphs\n",
    "# #         Use the detecting_minimals.ipynb file instead\n",
    "#         second_pass()\n",
    "        \n",
    "#         write_minimals_dict(nn, edcount, minimals_dict, path_prefix)\n",
    "#         write_partial_completed_dict(nn, edcount, completed_dict, path_prefix)\n",
    "#         write_completed_dict(completed_dict, path_prefix)\n",
    "\n",
    "        edcount -= 1\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d041fe5-f52c-4434-87d5-859a0a1c6122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
